{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOLGtVMoQGj3vBSBCpR0aWD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","import os\n","import pandas as pd\n","import torch\n","from torch.nn.utils.rnn import pad_sequence  # pad batch\n","from torch.utils.data import DataLoader, Dataset\n","from PIL import Image  # Load img\n","import torchvision.transforms as transforms\n","import spacy  # for tokenizer"],"metadata":{"id":"tVFyAmC5rqgI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 下載英文的字典庫\n","spacy_eng = spacy.load(\"en_core_web_sm\")\n","\n","class Vocabulary:\n","    # 這邊是先建立自己的字典，後面才會繼續增加\n","    def __init__(self, freq_threshold):\n","        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK>\"}\n","        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n","        self.freq_threshold = freq_threshold\n","\n","    def __len__(self):\n","        return len(self.itos)\n","\n","    # 把一文字先做 tokenizer 切成token ，再把token換成小寫\n","    @staticmethod\n","    def tokenizer_eng(text):\n","        return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n","\n","    \n","    def build_vocabulary(self, sentence_list):\n","        frequencies = {}\n","        idx = 4\n","\n","        # 每個句子\n","        for sentence in sentence_list:\n","            # 把句子透過tokenizer 轉換成words\n","            for word in self.tokenizer_eng(sentence):\n","                if word not in frequencies:\n","                    frequencies[word] = 1\n","\n","                else:\n","                    frequencies[word] += 1\n","                # words 要出現夠多次才會被加入到 vocabulary\n","                if frequencies[word] == self.freq_threshold:\n","                    self.stoi[word] = idx\n","                    self.itos[idx] = word\n","                    idx += 1\n","\n","    # 這個就是文字轉數值的地方，簡單來說文字先看 stoi 裡面有沒有，如果沒有的話就回傳<UNK>的數值\n","    def numericalize(self, text):\n","        tokenized_text = self.tokenizer_eng(text)\n","\n","        return [\n","            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"]\n","            for token in tokenized_text\n","        ]"],"metadata":{"id":"qrLOKBAZr2RP","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1664466375627,"user_tz":-480,"elapsed":32265,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}},"outputId":"a2bfe07f-680d-4339-c746-4ac786e08841"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f7133e58440>\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1510, in __del__\n","    self._shutdown_workers()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1474, in _shutdown_workers\n","    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n","  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 140, in join\n","    res = self._popen.wait(timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n","    if not wait([self.sentinel], timeout):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt: \n"]}]},{"cell_type":"code","source":["\n","# 這邊是建立圖片跟文字之間的關係\n","class FlickrDataset(Dataset):\n","    def __init__(self, root_dir, captions_file, transform=None, freq_threshold=5):\n","        self.root_dir = root_dir\n","        self.df = pd.read_csv(captions_file)\n","        self.transform = transform\n","\n","        # 載入圖片跟敘述\n","        self.imgs = self.df[\"image\"]\n","        self.captions = self.df[\"caption\"]\n","\n","        # 然後這邊就是設定 Vocab 的頻率threshold\n","        self.vocab = Vocabulary(freq_threshold)\n","        # 然後這邊就是設定把文字的部分丟進去建立字典\n","        self.vocab.build_vocabulary(self.captions.tolist())\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, index):\n","        caption = self.captions[index]\n","        img_id = self.imgs[index]\n","        img = Image.open(os.path.join(self.root_dir, img_id)).convert(\"RGB\")\n","\n","        if self.transform is not None:\n","            img = self.transform(img)\n","        # SOS => start of sentence\n","        numericalized_caption = [self.vocab.stoi[\"<SOS>\"]]\n","        # 這邊就是轉換成向量\n","        numericalized_caption += self.vocab.numericalize(caption)\n","        # EOS => end of sentence\n","        numericalized_caption.append(self.vocab.stoi[\"<EOS>\"])\n","\n","        # 因此這裡就是一個影像跟 一排vactor 的輸出（vactor 是文字轉出來的)\n","        return img, torch.tensor(numericalized_caption)\n","\n"],"metadata":{"id":"d4uOXp2stTvE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","class MyCollate:\n","    def __init__(self, pad_idx):\n","        self.pad_idx = pad_idx\n","\n","    def __call__(self, batch):\n","        imgs = [item[0].unsqueeze(0) for item in batch]\n","        imgs = torch.cat(imgs, dim=0)\n","        targets = [item[1] for item in batch]\n","        # 把他填充到等長\n","        targets = pad_sequence(targets, batch_first=False, padding_value=self.pad_idx)\n","\n","        return imgs, targets"],"metadata":{"id":"7DmvAfzhuljS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def get_loader(\n","    root_folder,\n","    annotation_file,\n","    transform,\n","    batch_size=32,\n","    num_workers=8,\n","    shuffle=True,\n","    pin_memory=True,\n","):\n","    dataset = FlickrDataset(root_folder, annotation_file, transform=transform)\n","\n","    pad_idx = dataset.dataset.stoi[\"<PAD>\"]\n","\n","    loader = DataLoader(\n","        dataset=dataset,\n","        batch_size=batch_size,\n","        num_workers=num_workers,\n","        shuffle=shuffle,\n","        pin_memory=pin_memory,\n","        collate_fn=MyCollate(pad_idx=pad_idx),\n","    )\n","\n","    return loader, dataset\n"],"metadata":{"id":"T3vmq_1Fum_r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%%time\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K5PhIgdLurGf","executionInfo":{"status":"ok","timestamp":1664466378571,"user_tz":-480,"elapsed":2950,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}},"outputId":"126ec3ec-af99-4d1b-c183-08aebc34a015"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","CPU times: user 43.1 ms, sys: 7.34 ms, total: 50.4 ms\n","Wall time: 2.74 s\n"]}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfUyLfA6_g-8","executionInfo":{"status":"ok","timestamp":1664467519306,"user_tz":-480,"elapsed":4,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}},"outputId":"84a25003-81c5-4237-e3aa-4b27eda11eb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<__main__.Vocabulary object at 0x7f70b7136110>\n"]}]},{"cell_type":"code","source":["\n","if __name__ == \"__main__\":\n","    transform = transforms.Compose(\n","        [transforms.Resize((224, 224)), transforms.ToTensor(),]\n","    )\n","\n","    loader, dataset = get_loader(\n","        \"/content/drive/MyDrive/Colab Notebooks/ithome/Flickr8k/Images/\", \n","        \"/content/drive/MyDrive/Colab Notebooks/ithome/Flickr8k/captions.txt\", \n","        transform=transform\n","    )\n","    print(len(dataset.vocab))\n","\n","    for idx, (imgs, captions) in enumerate(loader.head(0)):\n","        print(imgs.shape)\n","        print(captions.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":318},"id":"u5Q2eHlcuo9i","executionInfo":{"status":"error","timestamp":1664467570100,"user_tz":-480,"elapsed":1673,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}},"outputId":"5a44a276-32a8-44b9-af8d-7214e3674d23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2994\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-72-5cb8cbc97e46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'head'"]}]}]}