{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMnJrjf1xzfxeidEoBF7CMx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"-P0_Y9W5YOML","executionInfo":{"status":"ok","timestamp":1667281331749,"user_tz":-480,"elapsed":2500,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from PIL import Image\n","import torchvision.transforms as transforms\n","import torchvision.models as models\n","from torchvision.models import vgg19, VGG19_Weights\n","from torchvision.utils import save_image"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"htj4Cb1uaK2X","executionInfo":{"status":"ok","timestamp":1667281357690,"user_tz":-480,"elapsed":25946,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}},"outputId":"ea6cf508-3f48-4179-f490-a1f1d7a6896d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# model = models.vgg19(pretrained=True).features\n","model = vgg19(init_weights=VGG19_Weights.IMAGENET1K_V1).features\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T2ZY4zOXcRFL","executionInfo":{"status":"ok","timestamp":1667281359677,"user_tz":-480,"elapsed":2001,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}},"outputId":"937d250e-288a-4d6d-efb0-514d0f9285d5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Sequential(\n","  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (1): ReLU(inplace=True)\n","  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (3): ReLU(inplace=True)\n","  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (6): ReLU(inplace=True)\n","  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (8): ReLU(inplace=True)\n","  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (11): ReLU(inplace=True)\n","  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (13): ReLU(inplace=True)\n","  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (15): ReLU(inplace=True)\n","  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (17): ReLU(inplace=True)\n","  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (20): ReLU(inplace=True)\n","  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (22): ReLU(inplace=True)\n","  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (24): ReLU(inplace=True)\n","  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (26): ReLU(inplace=True)\n","  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (29): ReLU(inplace=True)\n","  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (31): ReLU(inplace=True)\n","  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (33): ReLU(inplace=True)\n","  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (35): ReLU(inplace=True)\n","  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",")\n"]}]},{"cell_type":"code","source":["\n","\n","class VGG(nn.Module):\n","    def __init__(self):\n","        super(VGG, self).__init__()\n","        # The first number x in convx_y gets added by 1 after it has gone\n","        # through a maxpool, and the second y if we have several conv layers\n","        # in between a max pool. These strings (0, 5, 10, ..) then correspond\n","        # to conv1_1, conv2_1, conv3_1, conv4_1, conv5_1 mentioned in NST paper\n","        self.chosen_features = [\"0\", \"5\", \"10\", \"19\", \"28\"]\n","\n","        # We don't need to run anything further than conv5_1 (the 28th module in vgg)\n","        # Since remember, we dont actually care about the output of VGG: the only thing\n","        # that is modified is the generated image (i.e, the input).\n","\n","\n","        \n","        # self.model = models.vgg19(pretrained=True).features[:29]\n","        self.model = vgg19(init_weights=VGG19_Weights.IMAGENET1K_V1).features[:29]\n","\n","    def forward(self, x):\n","        # Store relevant features\n","        features = []\n","\n","        # Go through each layer in model, if the layer is in the chosen_features,\n","        # store it in features. At the end we'll just return all the activations\n","        # for the specific layers we have in chosen_features\n","        for layer_num, layer in enumerate(self.model):\n","            x = layer(x)\n","\n","            if str(layer_num) in self.chosen_features:\n","                features.append(x)\n","\n","        return features\n","\n"],"metadata":{"id":"n6thR8zVYs2W","executionInfo":{"status":"ok","timestamp":1667281359677,"user_tz":-480,"elapsed":9,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","imsize = 356\n","\n","# Here we may want to use the Normalization constants used in the original\n","# VGG network (to get similar values net was originally trained on), but\n","# I found it didn't matter too much so I didn't end of using it. If you\n","# use it make sure to normalize back so the images don't look weird.\n","\n","loader = transforms.Compose(\n","    [\n","        transforms.Resize((imsize, imsize)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ]\n",")\n","\n","\n","def load_image(image_name):\n","    # 這邊會強制轉RGB，不然沒有加convert 的話有可能 chaanel = 4 \n","    image = Image.open(image_name).convert('RGB')\n","    image = loader(image).unsqueeze(0)\n","    return image.to(device)"],"metadata":{"id":"Ea7cYpJMaFkX","executionInfo":{"status":"ok","timestamp":1667284519737,"user_tz":-480,"elapsed":527,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","\n","original_img = load_image(\"/content/drive/MyDrive/Colab Notebooks/ithome/NST/peaceful_building.png\")\n","style_img = load_image(\"/content/drive/MyDrive/Colab Notebooks/ithome/NST/styles/style3.jpg\")\n","\n","# initialized generated as white noise or clone of original image.\n","# Clone seemed to work better for me.\n","\n","# generated = torch.randn(original_img.data.shape, device=device, requires_grad=True)\n","generated = original_img.clone().requires_grad_(True)\n","model = VGG().to(device).eval()"],"metadata":{"id":"JMBkjVMOaIB5","executionInfo":{"status":"ok","timestamp":1667286150868,"user_tz":-480,"elapsed":1729,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["\n","# Hyperparameters\n","total_steps = 8000\n","learning_rate = 0.001\n","alpha = 1\n","beta = 0.01\n","optimizer = optim.Adam([generated], lr=learning_rate)"],"metadata":{"id":"vJlDRCz9rDqj","executionInfo":{"status":"ok","timestamp":1667286154453,"user_tz":-480,"elapsed":501,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["\n","for step in range(total_steps):\n","    # Obtain the convolution features in specifically chosen layers\n","    generated_features = model(generated)\n","    original_img_features = model(original_img)\n","    style_features = model(style_img)\n","\n","    # Loss is 0 initially\n","    style_loss = original_loss = 0\n","\n","    # iterate through all the features for the chosen layers\n","    for gen_feature, orig_feature, style_feature in zip(\n","        generated_features, original_img_features, style_features\n","    ):\n","\n","        # batch_size will just be 1\n","        batch_size, channel, height, width = gen_feature.shape\n","        original_loss += torch.mean((gen_feature - orig_feature) ** 2)\n","        # Compute Gram Matrix of generated\n","        G = gen_feature.view(channel, height * width).mm(\n","            gen_feature.view(channel, height * width).t()\n","        )\n","        # Compute Gram Matrix of Style\n","        A = style_feature.view(channel, height * width).mm(\n","            style_feature.view(channel, height * width).t()\n","        )\n","        style_loss += torch.mean((G - A) ** 2)\n","\n","    total_loss = alpha * original_loss + beta * style_loss\n","    optimizer.zero_grad()\n","    total_loss.backward()\n","    optimizer.step()\n","\n","    if step % 200 == 0:\n","        print(total_loss)\n","        save_image(generated, \"/content/drive/MyDrive/Colab Notebooks/ithome/NST/generated_3.png\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":411},"id":"zS4ivNFzrIHR","executionInfo":{"status":"error","timestamp":1667286136140,"user_tz":-480,"elapsed":2329,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}},"outputId":"fe436dc6-5be2-4567-af0e-902e9c98f387"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(104074.7266, device='cuda:0', grad_fn=<AddBackward0>)\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-21-9889e93b6112>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0moriginal_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstyle_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["\n","for i in ['2','3','4','5','6','7']:\n","  original_img = load_image(\"/content/drive/MyDrive/Colab Notebooks/ithome/NST/peaceful_building.png\")\n","  style_img = load_image(f\"/content/drive/MyDrive/Colab Notebooks/ithome/NST/styles/style{i}.jpg\")\n","\n","  # initialized generated as white noise or clone of original image.\n","  # Clone seemed to work better for me.\n","\n","  # generated = torch.randn(original_img.data.shape, device=device, requires_grad=True)\n","  generated = original_img.clone().requires_grad_(True)\n","  model = VGG().to(device).eval()\n","\n","\n","  # Hyperparameters\n","  total_steps = 8000\n","  learning_rate = 0.001\n","  alpha = 1\n","  beta = 0.01\n","  optimizer = optim.Adam([generated], lr=learning_rate)\n","\n","\n","  for step in range(total_steps):\n","      # Obtain the convolution features in specifically chosen layers\n","      generated_features = model(generated)\n","      original_img_features = model(original_img)\n","      style_features = model(style_img)\n","\n","      # Loss is 0 initially\n","      style_loss = original_loss = 0\n","\n","      # iterate through all the features for the chosen layers\n","      for gen_feature, orig_feature, style_feature in zip(\n","          generated_features, original_img_features, style_features\n","      ):\n","\n","          # batch_size will just be 1\n","          batch_size, channel, height, width = gen_feature.shape\n","          original_loss += torch.mean((gen_feature - orig_feature) ** 2)\n","          # Compute Gram Matrix of generated\n","          G = gen_feature.view(channel, height * width).mm(\n","              gen_feature.view(channel, height * width).t()\n","          )\n","          # Compute Gram Matrix of Style\n","          A = style_feature.view(channel, height * width).mm(\n","              style_feature.view(channel, height * width).t()\n","          )\n","          style_loss += torch.mean((G - A) ** 2)\n","\n","      total_loss = alpha * original_loss + beta * style_loss\n","      optimizer.zero_grad()\n","      total_loss.backward()\n","      optimizer.step()\n","\n","      if step % 200 == 0:\n","          print(total_loss)\n","          save_image(generated, f\"/content/drive/MyDrive/Colab Notebooks/ithome/NST/generated_{i}.png\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C0WEnbLL_-F6","executionInfo":{"status":"ok","timestamp":1667295601117,"user_tz":-480,"elapsed":9379778,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}},"outputId":"65a4b586-5020-4922-bcd3-7a511e442ff2"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(481050.4375, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(295434.6250, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(189277.7969, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(127481.6328, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(89043.2422, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(64258.3477, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(47701.5820, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(36145.7656, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(27770.0273, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(21537.5664, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(16819.7969, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(13206.0801, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(10413.3467, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(8239.7461, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(6537.9360, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(5198.9028, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(4140.9717, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(3302.2986, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2635.5352, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2104.2485, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1680.1499, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1341.1598, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1069.9480, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(852.8466, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(679.0286, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(539.8925, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(428.5802, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(339.6092, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(268.5858, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(211.9805, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(166.9561, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(131.2226, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(102.9318, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(80.5914, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(62.9971, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(49.1823, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(38.3648, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(29.9197, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(23.3474, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(18.2456, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(584749.1875, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(274044.6562, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(139091.4531, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(75527.1562, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(43129.7891, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(25617.1836, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(15892.1816, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(10358.8174, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(7080.8867, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(5043.9141, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(3713.0107, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2802.2075, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2155.2488, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1682.1666, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1327.1965, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1055.1886, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(843.3477, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(676.9666, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(545.7457, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(441.8623, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(359.4320, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(293.8207, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(241.3235, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(199.1040, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(165.0064, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(137.2740, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(114.6153, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(96.0225, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(80.7145, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(68.0723, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(57.6495, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(49.0241, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(41.8337, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(35.8174, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(30.7613, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(26.5143, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(22.9298, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(19.8886, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(17.3044, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(15.0962, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(612998.8125, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(387314.7500, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(258100.1250, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(177881.8438, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(125921.7344, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(91390.3438, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(67749.5547, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(51050.0312, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(38962.7148, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(30048.3340, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(23377.1836, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(18324.2539, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(14456.9482, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(11469.7773, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(9144.6807, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(7322.7700, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(5887.9961, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(4752.5518, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(3849.1145, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(3126.2766, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2545.5303, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2077.1077, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1698.1367, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1390.6526, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1140.6324, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(936.8807, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(770.5080, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(634.4012, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(522.7799, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(431.1104, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(355.7126, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(293.5792, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(242.2977, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(199.9459, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(164.9744, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(136.1207, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(112.3274, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(92.7188, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(76.5748, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(63.2822, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(338715.1562, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(217075.2812, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(146175.0938, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(102085.5156, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(73211.5078, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(53570.0430, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(39846.0547, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(30051.0879, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(22934.9512, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(17687.0059, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(13765.6328, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(10801.2812, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(8537.2402, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(6791.9478, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(5436.0278, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(4373.3247, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(3533.3362, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2864.7024, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2329.2832, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1898.2808, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1549.8142, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1267.2441, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1037.6364, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(850.7799, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(698.4365, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(574.0158, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(472.2211, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(388.8359, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(320.4697, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(264.3968, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(218.3415, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(180.4669, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(149.2850, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(123.5797, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(102.3684, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(84.8399, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(70.3277, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(58.2957, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(48.3134, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(40.0268, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(29691.0293, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(11041.0664, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(5465.2983, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(3144.7246, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1943.9094, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1236.9392, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(785.2881, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(499.4486, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(322.2440, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(212.6458, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(144.3561, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(101.4532, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(74.1787, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(56.3331, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(44.2914, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(35.8630, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(29.7107, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(25.0524, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(21.4159, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(18.4973, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(16.1162, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(14.1374, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(12.4711, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(11.0464, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(9.8105, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(8.7330, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(7.7862, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(6.9500, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(6.2119, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(5.5599, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(4.9839, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(4.4751, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(4.0266, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(3.6295, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(3.2769, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2.9640, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2.6851, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2.4357, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2.2127, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2.0127, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(125568.7734, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(56649.1680, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(26385.2930, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(13347.4385, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(7334.1807, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(4332.4985, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(2730.8015, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1816.6298, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(1256.3970, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(885.9396, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(627.8916, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(447.7813, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(326.7805, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(248.3947, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(197.5589, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(163.1005, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(138.1254, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(118.8206, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(103.1438, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(90.0251, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(78.8116, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(69.0963, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(60.6202, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(53.1918, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(46.6506, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(40.8871, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(35.8058, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(31.3328, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(27.3953, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(23.9394, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(20.9182, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(18.2829, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(15.9945, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(14.0146, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(12.3065, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(10.8311, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(9.5561, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(8.4509, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(7.4914, device='cuda:0', grad_fn=<AddBackward0>)\n","tensor(6.6581, device='cuda:0', grad_fn=<AddBackward0>)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"HzI3s2FErQ3w","executionInfo":{"status":"ok","timestamp":1667286086475,"user_tz":-480,"elapsed":10,"user":{"displayName":"蔡岳峻","userId":"15002473577582326109"}}},"execution_count":18,"outputs":[]}]}